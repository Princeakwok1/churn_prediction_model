{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85c942e",
   "metadata": {},
   "source": [
    "# Module 4 — Churn Prediction: Model Development & Evaluation\n",
    "\n",
    "**Author:** Prince Nsidibe  \n",
    "**Course:** BAN6880 - Data Analytics Capstone\n",
    "\n",
    "This notebook trains and evaluates classification models to predict customer churn using the finalized dataset from Milestone 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports and settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598ae6f",
   "metadata": {},
   "source": [
    "## 2) Load finalized dataset\n",
    "\n",
    "Update `DATA_PATH` below if your finalized dataset is in a different location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01107e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed/finalized_churn_dataset.csv'  # change if needed\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Finalized dataset not found at {DATA_PATH}. Please run churn_eda.ipynb or update DATA_PATH.\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Loaded dataset shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43aff1",
   "metadata": {},
   "source": [
    "## 3) Quick data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c92a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic checks\n",
    "print('Columns:', list(df.columns))\n",
    "print('\\nDtypes:\\n', df.dtypes)\n",
    "print('\\nMissing values per column:\\n', df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2cd91",
   "metadata": {},
   "source": [
    "## 4) Feature selection\n",
    "\n",
    "Drop identifiers and choose label (`churn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbeaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'churn'  # as created in Milestone 1\n",
    "drop_cols = ['customer_id', 'signup_date', 'last_order_date', 'last_login']\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "X = df.drop(columns=[label] + drop_cols)\n",
    "y = df[label].astype(int)\n",
    "print('X shape:', X.shape, 'y distribution:\\n', y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d66133",
   "metadata": {},
   "source": [
    "## 5) Train-test split (stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd278759",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20758bb2",
   "metadata": {},
   "source": [
    "## 6) Identify numeric and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "print('Numeric cols:', numeric_cols)\n",
    "print('Categorical cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ac4c3",
   "metadata": {},
   "source": [
    "## 7) Preprocessing pipelines\n",
    "\n",
    "StandardScaler for numeric features and OneHotEncoder for categoricals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "], remainder='drop')\n",
    "print('Preprocessor ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97debd",
   "metadata": {},
   "source": [
    "## 8) Baseline model — Logistic Regression\n",
    "\n",
    "Use class_weight='balanced' to mitigate imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbe088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[('preproc', preprocessor),\n",
    "                           ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "y_proba_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
    "print('Logistic Regression')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f360c6",
   "metadata": {},
   "source": [
    "## 9) Option: SMOTE + Logistic Regression\n",
    "\n",
    "Compare resampling approach versus class_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sm_lr = ImbPipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
    "])\n",
    "pipe_sm_lr.fit(X_train, y_train)\n",
    "y_pred_sm = pipe_sm_lr.predict(X_test)\n",
    "y_proba_sm = pipe_sm_lr.predict_proba(X_test)[:,1]\n",
    "print('SMOTE + LR')\n",
    "print(classification_report(y_test, y_pred_sm))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076a241",
   "metadata": {},
   "source": [
    "## 10) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2193cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(steps=[('preproc', preprocessor),\n",
    "                          ('clf', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipe_rf.predict(X_test)\n",
    "y_proba_rf = pipe_rf.predict_proba(X_test)[:,1]\n",
    "print('Random Forest')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a260d4",
   "metadata": {},
   "source": [
    "## 11) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_xgb = Pipeline(steps=[('preproc', preprocessor),\n",
    "                           ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE))])\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = pipe_xgb.predict(X_test)\n",
    "y_proba_xgb = pipe_xgb.predict_proba(X_test)[:,1]\n",
    "print('XGBoost')\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81875ec2",
   "metadata": {},
   "source": [
    "## 12) ROC Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29397c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for name, proba in [('LogReg', y_proba_lr), ('RF', y_proba_rf), ('XGB', y_proba_xgb)]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc_score(y_test, proba):.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc554a2",
   "metadata": {},
   "source": [
    "## 13) Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for name, proba in [('LogReg', y_proba_lr), ('RF', y_proba_rf), ('XGB', y_proba_xgb)]:\n",
    "    prec, rec, _ = precision_recall_curve(y_test, proba)\n",
    "    ap = average_precision_score(y_test, proba)\n",
    "    plt.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e284a",
   "metadata": {},
   "source": [
    "## 14) Hyperparameter Tuning (XGBoost)\n",
    "\n",
    "GridSearchCV optimizing ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [3, 5],\n",
    "    'clf__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "gs = GridSearchCV(pipe_xgb, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params:', gs.best_params_)\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_proba_best = best_model.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print('ROC-AUC (best):', roc_auc_score(y_test, y_proba_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1a90b",
   "metadata": {},
   "source": [
    "## 15) Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e712148",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "try:\n",
    "    num_names = numeric_cols\n",
    "    if cat_cols:\n",
    "        ohe = best_model.named_steps['preproc'].named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "    else:\n",
    "        cat_names = []\n",
    "    feature_names = list(num_names) + cat_names\n",
    "except Exception as e:\n",
    "    print('Could not build feature names:', e)\n",
    "\n",
    "try:\n",
    "    importances = best_model.named_steps['clf'].feature_importances_\n",
    "    fi = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    fi = fi.sort_values('importance', ascending=False).head(20)\n",
    "    print(fi)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(fi['feature'][::-1], fi['importance'][::-1])\n",
    "    plt.title('Top Feature Importances')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Could not extract feature importances:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83a4ca",
   "metadata": {},
   "source": [
    "## 16) Save best model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(best_model, '../models/best_xgb_model.pkl')\n",
    "results = {\n",
    "    'model': ['LogisticRegression', 'RandomForest', 'XGBoost', 'XGBoost_Tuned'],\n",
    "    'roc_auc': [\n",
    "        roc_auc_score(y_test, y_proba_lr),\n",
    "        roc_auc_score(y_test, y_proba_rf),\n",
    "        roc_auc_score(y_test, y_proba_xgb),\n",
    "        roc_auc_score(y_test, y_proba_best)\n",
    "    ]\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('../models/model_results_summary.csv', index=False)\n",
    "print('Saved model and results to ../models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf123a1",
   "metadata": {},
   "source": [
    "## 17) Conclusion & Next Steps\n",
    "\n",
    "- Best model (tuned XGBoost) saved.\n",
    "- Key metrics: ROC-AUC, Precision/Recall reported above.\n",
    "- Next steps: productionize model, set monitoring, A/B test retention campaigns.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
