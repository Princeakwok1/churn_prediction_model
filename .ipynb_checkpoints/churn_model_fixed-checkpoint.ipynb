{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d712d78",
   "metadata": {},
   "source": [
    "# Module 4 — Churn Prediction: Model Development & Evaluation\n",
    "\n",
    "**Author:** Prince Nsidibe  \n",
    "**Course:** BAN6880 - Data Analytics Capstone\n",
    "\n",
    "This notebook trains and evaluates classification models to predict customer churn using the finalized dataset from Milestone 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74053f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports and settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "print('scikit-learn version:', sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf7d37",
   "metadata": {},
   "source": [
    "## 2) Load finalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c843cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed/finalized_churn_dataset.csv'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Finalized dataset not found at {DATA_PATH}. Please run churn_eda.ipynb or update DATA_PATH.\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Loaded dataset shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0145b2",
   "metadata": {},
   "source": [
    "## 3) Quick data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns:', list(df.columns))\n",
    "print('\\nDtypes:\\n', df.dtypes)\n",
    "print('\\nMissing values per column:\\n', df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dab54",
   "metadata": {},
   "source": [
    "## 4) Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e10280",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'churn'\n",
    "drop_cols = ['customer_id', 'signup_date', 'last_order_date', 'last_login']\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "X = df.drop(columns=[label] + drop_cols)\n",
    "y = df[label].astype(int)\n",
    "print('X shape:', X.shape, 'y distribution:\\n', y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de0a57",
   "metadata": {},
   "source": [
    "## 5) Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa908a14",
   "metadata": {},
   "source": [
    "## 6) Identify numeric and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6096d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "print('Numeric cols:', numeric_cols)\n",
    "print('Categorical cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a6362",
   "metadata": {},
   "source": [
    "## 7) Preprocessing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "if sklearn.__version__ >= \"1.2\":\n",
    "    cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "else:\n",
    "    cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "print('Preprocessor ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69107a3",
   "metadata": {},
   "source": [
    "## 8) Baseline model — Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[('preproc', preprocessor),\n",
    "                           ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "y_proba_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
    "print('Logistic Regression')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2062a1",
   "metadata": {},
   "source": [
    "## 9) SMOTE + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f31dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sm_lr = ImbPipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
    "])\n",
    "pipe_sm_lr.fit(X_train, y_train)\n",
    "y_pred_sm = pipe_sm_lr.predict(X_test)\n",
    "y_proba_sm = pipe_sm_lr.predict_proba(X_test)[:,1]\n",
    "print('SMOTE + LR')\n",
    "print(classification_report(y_test, y_pred_sm))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2caed",
   "metadata": {},
   "source": [
    "## 10) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(steps=[('preproc', preprocessor),\n",
    "                          ('clf', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipe_rf.predict(X_test)\n",
    "y_proba_rf = pipe_rf.predict_proba(X_test)[:,1]\n",
    "print('Random Forest')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206f385",
   "metadata": {},
   "source": [
    "## 11) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd056f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_xgb = Pipeline(steps=[('preproc', preprocessor),\n",
    "                           ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE))])\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = pipe_xgb.predict(X_test)\n",
    "y_proba_xgb = pipe_xgb.predict_proba(X_test)[:,1]\n",
    "print('XGBoost')\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ebf4f",
   "metadata": {},
   "source": [
    "## 12) ROC Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d56439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for name, proba in [('LogReg', y_proba_lr), ('RF', y_proba_rf), ('XGB', y_proba_xgb)]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc_score(y_test, proba):.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf9811",
   "metadata": {},
   "source": [
    "## 13) Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for name, proba in [('LogReg', y_proba_lr), ('RF', y_proba_rf), ('XGB', y_proba_xgb)]:\n",
    "    prec, rec, _ = precision_recall_curve(y_test, proba)\n",
    "    ap = average_precision_score(y_test, proba)\n",
    "    plt.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c07e3",
   "metadata": {},
   "source": [
    "## 14) Hyperparameter Tuning (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [3, 5],\n",
    "    'clf__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "gs = GridSearchCV(pipe_xgb, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params:', gs.best_params_)\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_proba_best = best_model.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print('ROC-AUC (best):', roc_auc_score(y_test, y_proba_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848b448",
   "metadata": {},
   "source": [
    "## 15) Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6df896",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "try:\n",
    "    num_names = numeric_cols\n",
    "    if cat_cols:\n",
    "        ohe = best_model.named_steps['preproc'].named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "    else:\n",
    "        cat_names = []\n",
    "    feature_names = list(num_names) + cat_names\n",
    "except Exception as e:\n",
    "    print('Could not build feature names:', e)\n",
    "\n",
    "try:\n",
    "    importances = best_model.named_steps['clf'].feature_importances_\n",
    "    fi = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    fi = fi.sort_values('importance', ascending=False).head(20)\n",
    "    print(fi)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(fi['feature'][::-1], fi['importance'][::-1])\n",
    "    plt.title('Top Feature Importances')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Could not extract feature importances:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46588cc8",
   "metadata": {},
   "source": [
    "## 16) Save best model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9744f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(best_model, '../models/best_xgb_model.pkl')\n",
    "results = {\n",
    "    'model': ['LogisticRegression', 'RandomForest', 'XGBoost', 'XGBoost_Tuned'],\n",
    "    'roc_auc': [\n",
    "        roc_auc_score(y_test, y_proba_lr),\n",
    "        roc_auc_score(y_test, y_proba_rf),\n",
    "        roc_auc_score(y_test, y_proba_xgb),\n",
    "        roc_auc_score(y_test, y_proba_best)\n",
    "    ]\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('../models/model_results_summary.csv', index=False)\n",
    "print('Saved model and results to ../models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf857ff",
   "metadata": {},
   "source": [
    "## 17) Conclusion & Next Steps\n",
    "\n",
    "- Best model (tuned XGBoost) saved.\n",
    "- Key metrics: ROC-AUC, Precision/Recall reported above.\n",
    "- Next steps: productionize model, set monitoring, A/B test retention campaigns.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
